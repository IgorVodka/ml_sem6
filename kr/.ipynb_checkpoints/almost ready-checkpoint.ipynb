{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3d00d838479b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_available_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Globally-importable utils.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tensorflow'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Try and load external backend.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(dirname, file):\n",
    "    arr = np.array(Image.open('./' + dirname + '/' + file + '.jpg').convert('L'))\n",
    "    return arr.reshape(400, 300, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 300, 1)"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./dataset.csv')\n",
    "dataset['image'] = dataset.apply(lambda x: load_image('images', x.file), axis=1)\n",
    "dataset['label'] = dataset.apply(lambda x: np.array([x.country == 'ru', x.country == 'uk']), axis=1)\n",
    "dataset.iloc[0].image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten\n",
    "\n",
    "N_IMAGES = len(dataset)\n",
    "IMG_W = 400\n",
    "IMG_H = 300\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), use_bias=False, input_shape=(IMG_W, IMG_H, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), use_bias=False))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), use_bias=False))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3,3), use_bias=False))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3,3), use_bias=False))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), use_bias=False))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(2, use_bias=False))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 300, 1)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['image'].iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras import losses\n",
    "\n",
    "model.compile(loss=losses.mean_squared_error, optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape is (3114, 400, 300, 1)\n",
      "y shape is (3114, 2)\n"
     ]
    }
   ],
   "source": [
    "x = np.array(dataset['image'].tolist())\n",
    "y = np.array(dataset['label'].tolist())\n",
    "print('x shape is', x.shape)\n",
    "print('y shape is', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold:  1\n",
      "Train on 2521 samples, validate on 281 samples\n",
      "Epoch 1/3\n",
      "2521/2521 [==============================] - 499s 198ms/step - loss: 0.2354 - val_loss: 0.2364\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23637, saving model to checkpoint.h5\n",
      "Epoch 2/3\n",
      "  20/2521 [..............................] - ETA: 7:14 - loss: 0.1785"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-386-a8c034950dfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training on fold: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mt_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmodel_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=======\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\n\\n\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-386-a8c034950dfe>\u001b[0m in \u001b[0;36mfit_and_evaluate\u001b[0;34m(t_x, val_x, t_y, val_y, used_epochs, used_batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mused_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     results = model.fit(t_x, t_y, epochs=used_epochs, batch_size=used_batch_size, callbacks=[early_stopping, model_checkpoint], \n\u001b[0;32m---> 18\u001b[0;31m               verbose=1, validation_split=0.1)  \n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Val Score: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# set early stopping criteria\n",
    "patience = 5 # this is the number of epochs with no improvement after which the training will stop\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience, verbose=1)\n",
    "\n",
    "#define the model checkpoint callback -> this will keep on saving the model as a physical file\n",
    "model_checkpoint = ModelCheckpoint('./checkpoint.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "n_folds = 3\n",
    "epochs = 3\n",
    "batch_size = 10\n",
    "model_history = []\n",
    "\n",
    "def fit_and_evaluate(t_x, val_x, t_y, val_y, used_epochs, used_batch_size):\n",
    "    results = model.fit(t_x, t_y, epochs=used_epochs, batch_size=used_batch_size, callbacks=[early_stopping, model_checkpoint], \n",
    "              verbose=1, validation_split=0.1)  \n",
    "    print(\"Val Score: \", model.evaluate(val_x, val_y))\n",
    "    return results\n",
    "\n",
    "for i in range(n_folds):\n",
    "    print(\"Training on fold: \", i+1)\n",
    "    t_x, val_x, t_y, val_y = train_test_split(x, y, test_size=0.1, random_state = np.random.randint(1,1000, 1)[0])\n",
    "    model_history.append(fit_and_evaluate(t_x, val_x, t_y, val_y, epochs, batch_size))\n",
    "    print(\"=======\" * 12, end=\"\\n\\n\\n\")\n",
    "\n",
    "model.fit(x, y, verbose=1, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-381-b5fc7bc98d2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracies vs Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Fold 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Fold 2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Fold 3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Accuracies vs Epochs')\n",
    "plt.plot(model_history[0].history['acc'], label='Training Fold 1')\n",
    "plt.plot(model_history[1].history['acc'], label='Training Fold 2')\n",
    "plt.plot(model_history[2].history['acc'], label='Training Fold 3')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Train Accuracy vs Val Accuracy')\n",
    "plt.plot(model_history[0].history['acc'], label='Train Accuracy Fold 1', color='black')\n",
    "plt.plot(model_history[0].history['val_acc'], label='Val Accuracy Fold 1', color='black', linestyle = \"dashdot\")\n",
    "plt.plot(model_history[1].history['acc'], label='Train Accuracy Fold 2', color='red', )\n",
    "plt.plot(model_history[1].history['val_acc'], label='Val Accuracy Fold 2', color='red', linestyle = \"dashdot\")\n",
    "plt.plot(model_history[2].history['acc'], label='Train Accuracy Fold 3', color='green', )\n",
    "plt.plot(model_history[2].history['val_acc'], label='Val Accuracy Fold 3', color='green', linestyle = \"dashdot\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_GzkYw3fNKRNgyYOX7h4MQ is likely from Russia (real country is ru)',\n",
       " 'K-sxsEjhPfJZ_mmfRNz95Q is likely from Russia (real country is ru)',\n",
       " 'eOPlQcQptHKaFsabiE0rnA is likely from UK (real country is uk)',\n",
       " 'e12MKDZDbFubDSCrVwkOkQ is likely from UK (real country is uk)',\n",
       " 'H496H2jKHHnqtWQNpoW7og is likely from Russia (real country is uk)',\n",
       " 'zJTpfHFY4Ps84VnxDtrc8A is likely from Russia (real country is ru)',\n",
       " 'tzGMC8iD_iAjFvYypJjsOw is likely from UK (real country is ru)',\n",
       " 'HdpPx_MKb5RNy0mQuSvRXw is likely from UK (real country is uk)',\n",
       " 'KnWfahFs4vueLx7mpjzDmg is likely from UK (real country is uk)',\n",
       " 'F-dEXGxeSdHhUHktth8pRA is likely from Russia (real country is ru)',\n",
       " 'pxbAN6zZGhuz8LzyOAU1Jw is likely from Russia (real country is ru)',\n",
       " 'LA90T9dV-xeAxraX4cFHIg is likely from UK (real country is uk)',\n",
       " 'PDLCOkGJyTvGOFbqnimPlA is likely from UK (real country is uk)',\n",
       " 'JN2XKPAxBKU8A8eyDOKhyA is likely from UK (real country is uk)',\n",
       " 'Ele_oCqcb911WRQzlW6B8g is likely from Russia (real country is uk)',\n",
       " 'd_j6F_rGszztDVtHyj19eA is likely from UK (real country is ru)',\n",
       " 'xJwwoFuyDcq8x2sw4I3GGA is likely from UK (real country is ru)',\n",
       " 'nVLnQho5Qpu_JIdeSzctGA is likely from Russia (real country is ru)',\n",
       " '_vNY5I4bZbCXGMDA6QaSzA is likely from Russia (real country is ru)',\n",
       " 'I3vM7Pif8GK9tmDXjqVGMA is likely from Russia (real country is ru)',\n",
       " '1GfBKoj4KnEAX3TZA-q8Ig is likely from Russia (real country is ru)',\n",
       " 'S3ny7JPvhuG8xpUu75ph_g is likely from Russia (real country is ru)',\n",
       " 'JScNmxJVR3qg8OPSuisR4g is likely from UK (real country is uk)',\n",
       " 'uUxqwznNibfdDSrFpQNraQ is likely from UK (real country is uk)',\n",
       " 'MeMR7SXOclZDTt2GBPqS6w is likely from UK (real country is ru)',\n",
       " '2ZZ2fyMWCdwRg9lD2nGmBQ is likely from UK (real country is uk)',\n",
       " 'ilnzkUIwZroOrfoIXJJjtA is likely from UK (real country is ru)',\n",
       " 'MIF9mSEEqJY5_GzgEiNGCg is likely from Russia (real country is uk)',\n",
       " '_n__L-ak8NuvE_d5fbC5WQ is likely from Russia (real country is ru)',\n",
       " 'hyHlLEBQNgxsqqzosYzbcw is likely from UK (real country is uk)',\n",
       " 'H6GiO8iDtHR8klSVj_88jg is likely from UK (real country is ru)',\n",
       " 'bs1-69c88tOPeblUaq7XVg is likely from UK (real country is ru)',\n",
       " 'Kw7ij41k2FRn9NOmQEw5jg is likely from UK (real country is uk)',\n",
       " 'ILBaAzwBQhLsjt2wvPlvgg is likely from UK (real country is uk)',\n",
       " 'xNbRO-tfJmufXCSsm7V_UA is likely from UK (real country is uk)',\n",
       " 'hjVc0aKvm4lEOMDbNGtXMw is likely from Russia (real country is uk)',\n",
       " 'IVEiCFrzAIML62aVf8mT_A is likely from UK (real country is ru)',\n",
       " 'L9pgUoHxkwXxu8y-YMYbsw is likely from UK (real country is uk)',\n",
       " 'nyrIYs1qUikSVyCD04LT4Q is likely from UK (real country is uk)',\n",
       " '4UL6jAuPMNhIwJCe6WnFEA is likely from UK (real country is uk)',\n",
       " 'H4j5BEnnb-nHFAq09xoDgQ is likely from UK (real country is uk)',\n",
       " 'ovhHARiBwalfqRXaTrgTGw is likely from UK (real country is uk)',\n",
       " 'P6qgnrvml3J7PXrzvOMKBQ is likely from Russia (real country is ru)',\n",
       " 'UkEo6HQKaHmS2eXkDLpXHQ is likely from Russia (real country is ru)',\n",
       " '6upB8VMD3XLF-oPiZlfw7Q is likely from UK (real country is ru)',\n",
       " 'DIDcYjS0byhYj5K2xCQ8_g is likely from UK (real country is ru)',\n",
       " 'dHvaEmA4kUkoSdmTGT2YnQ is likely from Russia (real country is uk)',\n",
       " 'ggtTc8nQdy6ycmRX68mIjw is likely from UK (real country is uk)',\n",
       " 'fdxdyTyMfRS6IvCsKiHYwA is likely from UK (real country is uk)',\n",
       " '-pBrL6-uafimx9t1c3a0tA is likely from UK (real country is uk)',\n",
       " 'C52jI7wurJDig_M2BiTATQ country is unidentified (real country is ru)',\n",
       " 'QBOp6fm8U-5C3SNty04UVg is likely from UK (real country is uk)',\n",
       " 'meId7zXkJJSNHulmmrcVVQ is likely from Russia (real country is ru)',\n",
       " 'bkOGc6a70fY0CmlmvF_VZg is likely from Russia (real country is ru)',\n",
       " '7HDGIT3LJtk5EqP-y06_cQ is likely from Russia (real country is ru)',\n",
       " 'Q-yvK-9SQc_cRSBT5pbNIQ is likely from UK (real country is uk)',\n",
       " 'eHlQBwagIHsPny9dvlA9_g is likely from UK (real country is uk)',\n",
       " 'ZAU0Q14NxaTwBIncAvLLqQ is likely from Russia (real country is uk)',\n",
       " 'TCqtKE1qag7cZgnXoLOyBA is likely from UK (real country is uk)',\n",
       " 'YbQBknTTvznsJE9gRMxtzQ is likely from Russia (real country is uk)',\n",
       " 'rYB6ilwrw_Qho-hRK_M0uQ is likely from Russia (real country is uk)',\n",
       " '7v1B03AVaEz3g-OOmxVCmw is likely from Russia (real country is ru)',\n",
       " 'BxsY6_Gwp3YxeauzlZcy7w is likely from UK (real country is uk)',\n",
       " 'qY5eC9wKwwYuTwXlDLMR7g is likely from UK (real country is ru)',\n",
       " 'eYNHReAuoX0LURhV03DNfg is likely from Russia (real country is ru)',\n",
       " 'h24EAE37bUTASqgtVitP0A is likely from Russia (real country is uk)',\n",
       " 'YBLyWHkJ9bo8H0cHF-MxQg is likely from UK (real country is uk)',\n",
       " 'Q8xaXG92fNFAgAxMc9hErw is likely from Russia (real country is ru)',\n",
       " '3DPmMtrG_SQYP8klklFO7w is likely from UK (real country is ru)',\n",
       " 'x0dXnocY26mr93gQ-zG5YA is likely from Russia (real country is uk)',\n",
       " 'nTriAg7j8CXSHiiuWQq2cw is likely from Russia (real country is uk)',\n",
       " 'ySivQnToi21rY7RBK-Bgwg is likely from UK (real country is uk)',\n",
       " '-vByhfG3DuMR4KhpCx2E_g is likely from UK (real country is uk)',\n",
       " '1MPaKLtqj72rklY-qbLvDA is likely from Russia (real country is ru)',\n",
       " 'srg6fn6_HcBOF6llKyw8xg is likely from Russia (real country is ru)',\n",
       " 'N71Fz2qIiqEWut-5TkXwYg is likely from UK (real country is uk)',\n",
       " 'IJKXDJhbSf7rpekObIIT9w is likely from Russia (real country is uk)',\n",
       " 'Kuz8wuERaPBF30uyniwE5A is likely from Russia (real country is uk)',\n",
       " '5zD5Xzi62reSfypw-cI7Bw is likely from UK (real country is uk)',\n",
       " 'EyY9P6Ja6mfOLH8E4wvUmQ is likely from Russia (real country is ru)',\n",
       " '3k1_zCavkIR8tpYToClxwA is likely from Russia (real country is ru)',\n",
       " '5vqRbneJ-6XUg1An5IbBqg is likely from Russia (real country is uk)',\n",
       " 'R1NoZkxGaqt1kr2wKfQ7Uw is likely from Russia (real country is ru)',\n",
       " '7O6t18jdpZxZ-ytrAgryLA is likely from UK (real country is ru)',\n",
       " 'X1IQuFQIu1ejzCIcP9wINw is likely from UK (real country is uk)',\n",
       " '0GO0wOHnopXCWd5kCJ76VQ is likely from Russia (real country is ru)',\n",
       " 'BdTdRFxPzm_nXYnOSxviyQ is likely from Russia (real country is uk)',\n",
       " 'yf3Ykp3b9QY53m1JyKVmsw is likely from UK (real country is uk)',\n",
       " 'HK7GMEkd6EkYwlpHmsl0VA is likely from Russia (real country is uk)',\n",
       " 'G8b5trHNQHvPwplXIq0r0Q is likely from UK (real country is uk)',\n",
       " 'pgbf0PHHIyrqjKsk89y5yA is likely from UK (real country is ru)',\n",
       " 'KZaDFqAorfLebmKalEhRfQ is likely from UK (real country is uk)',\n",
       " 'km_sQt5db4o2x7OxiJjXMw is likely from Russia (real country is ru)',\n",
       " 'Uk7x_1AS1mRLi-Kjll4FKQ is likely from Russia (real country is ru)',\n",
       " 'ZpuyEw6tsqcOBFO80Z9rHg is likely from UK (real country is ru)',\n",
       " '_Jz6yrzc9rt8UWPGWk68IQ is likely from Russia (real country is uk)',\n",
       " 'qo5uGmEFm3o4UXZgjwnTtQ country is unidentified (real country is uk)',\n",
       " 'jqlVsuDxqyo45r4IyjBzKw is likely from Russia (real country is ru)',\n",
       " 'wngHH4kWgBq7aO-7PXljUQ is likely from UK (real country is ru)',\n",
       " 'B3NyUx7YKa1ofjyCoxP5VQ is likely from Russia (real country is ru)',\n",
       " 'evHxtoT2RE-HLFphL6GxWQ is likely from UK (real country is uk)',\n",
       " 'EEw3mlfF7FSGVH1k1F-BBA is likely from Russia (real country is ru)',\n",
       " 'bLyQjQDMFhsxCfLQKPe5bA is likely from UK (real country is ru)',\n",
       " 'vRRx3MD7gyCoyU-2XhECbw is likely from UK (real country is ru)',\n",
       " 'DMnY1nYGAMSbZONu04KK3w is likely from UK (real country is ru)',\n",
       " 'RsSIzNneKkyV9LSVv6pBnw is likely from UK (real country is uk)',\n",
       " 'V38Z9GoRIL6Iaze_Zajdbw is likely from UK (real country is uk)',\n",
       " 'w88dcpXdtxSFseMkyJLoLg is likely from UK (real country is uk)',\n",
       " '_9JI67FkuOUoleA1lKtFXw is likely from UK (real country is uk)',\n",
       " 'HYHp7ejv4hoocjAHDnTGEw is likely from Russia (real country is ru)',\n",
       " 'l1eZKFaOlCWqlfyWIjAzSg is likely from UK (real country is uk)']"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = pd.read_csv('./dataset_test.csv')\n",
    "\n",
    "predictions = []\n",
    "\n",
    "guesses = 0\n",
    "unidentified = 0\n",
    "\n",
    "for index, row in test_images.iterrows():\n",
    "    image = row['file']\n",
    "    real_country = row['country']\n",
    "    \n",
    "    test_image = load_image('images_test', image)\n",
    "    prediction = model.predict(test_image.reshape(1, 400, 300, 1))\n",
    "    if prediction[0][0] > 0.51:\n",
    "        predictions.append(image + \" is likely from Russia (real country is \" + real_country + \")\")\n",
    "        guessed_country = 'ru'\n",
    "    elif prediction[0][1] > 0.51:\n",
    "        predictions.append(image + \" is likely from UK (real country is \" + real_country + \")\")\n",
    "        guessed_country = 'uk'\n",
    "    else:\n",
    "        predictions.append(image + \" country is unidentified (real country is \" + real_country + \")\")\n",
    "        guessed_country = None\n",
    "    \n",
    "    if guessed_country == real_country:\n",
    "        guesses += 1\n",
    "    elif guessed_country is None:\n",
    "        unidentified += 1\n",
    "    \n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Угадано 73\n",
      "Неизвестно 2\n",
      "Всего 111\n",
      "Точность: 65.76576576576578 %\n"
     ]
    }
   ],
   "source": [
    "print('Угадано', guesses)\n",
    "print('Неизвестно', unidentified)\n",
    "print('Всего', len(test_images))\n",
    "print('Точность:', guesses / len(test_images) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
